{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1cd1c5",
   "metadata": {},
   "source": [
    "\n",
    "# MVSA-Single Text Sentiment Classification (TF‑IDF + Logistic Regression)\n",
    "### Preprocessing Ablation Study (Raw vs Individual Steps vs Full Pipeline)\n",
    "\n",
    "This notebook implements a **text-only** sentiment classification project on the **MVSA-Single** dataset and runs **controlled comparison experiments** to measure how different preprocessing steps improve a **Logistic Regression** model.\n",
    "\n",
    "## Goals\n",
    "- Use **only** a **Logistic Regression** classifier.\n",
    "- Compare **Raw text** vs **individual preprocessing steps** vs **Full preprocessing** on the **same English subset**.\n",
    "- Report improvements using **Accuracy** and **Macro-F1** (Macro-F1 is more informative under class imbalance).\n",
    "\n",
    "## Experiments\n",
    "All experiments share the same:\n",
    "- English subset selection\n",
    "- Train/Test split (fixed random seed, stratified)\n",
    "- TF-IDF settings\n",
    "- Logistic Regression hyperparameters\n",
    "\n",
    "We change **only one factor** at a time (except the **Full** experiment which combines all steps).\n",
    "\n",
    "| ID | Description | Text Transform | Training Change |\n",
    "|---|---|---|---|\n",
    "| E0 | Raw baseline (English subset) | None | None |\n",
    "| E1 | Remove `@/#/url` tokens | ✅ | None |\n",
    "| E2 | Slang expansion | ✅ | None |\n",
    "| E3 | Class weighting | None | `class_weight=\"balanced\"` |\n",
    "| E4 | **FULL**: Remove `@/#/url` + Slang expansion + Class weighting | ✅ | `class_weight=\"balanced\"` |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c182f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T07:45:32.154629Z",
     "start_time": "2026-02-06T07:45:32.146960Z"
    }
   },
   "source": [
    "# =========================\n",
    "# 1) Setup & Imports\n",
    "# =========================\n",
    "# This notebook is designed to be reproducible:\n",
    "# - Fixed random seed for splitting\n",
    "# - Deterministic language detection seed (if langdetect is installed)\n",
    "# - All key parameters are defined in one place\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Callable, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Make langdetect deterministic if available\n",
    "try:\n",
    "    from langdetect import DetectorFactory\n",
    "    DetectorFactory.seed = 0\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Imports complete.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "ea36b191",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load MVSA-Single (Text + Text Sentiment Labels)\n",
    "\n",
    "The dataset is from kaggle https://www.kaggle.com/datasets/vincemarcs/mvsasingle.\n",
    "\n",
    "Inside it, the MVSA-Single structure typically includes:\n",
    "- `labelResultAll.txt` : tab-separated, contains labels for each ID (format: `text,image`)\n",
    "- `data/<ID>.txt` : raw tweet text for each sample\n",
    "\n",
    "We will:\n",
    "1. download the dataset\n",
    "2. Parse the **text sentiment** label (the first value in `text,image`)\n",
    "3. Read tweet texts from `data/*.txt`\n",
    "4. Merge into a single DataFrame: **(text, label)**\n",
    "\n",
    "> Note: This notebook focuses on **text-only** modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca342344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T07:45:36.686923Z",
     "start_time": "2026-02-06T07:45:35.688974Z"
    }
   },
   "source": [
    "# =========================\n",
    "# 2) Dataset Extraction\n",
    "# =========================\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vincemarcs/mvsasingle\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "MVSA_ROOT = Path(os.path.join(path, \"MVSA_Single\"))\n",
    "LABEL_FILE = Path(os.path.join(MVSA_ROOT, \"labelResultAll.txt\"))\n",
    "DATA_DIR = Path(os.path.join(MVSA_ROOT, \"data\"))\n",
    "\n",
    "print(\"MVSA_ROOT:\", MVSA_ROOT)\n",
    "print(\"LABEL_FILE:\", LABEL_FILE)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "# Load label file: columns are typically [\"ID\", \"text,image\"]\n",
    "labels = pd.read_csv(LABEL_FILE, sep=\"\\t\", engine=\"python\")\n",
    "labels.columns = [c.strip() for c in labels.columns]\n",
    "\n",
    "# Extract *text* sentiment label from \"text,image\" column\n",
    "# Example row: \"neutral,positive\"  -> text label = \"neutral\"\n",
    "labels[\"label\"] = labels[\"text,image\"].astype(str).str.split(\",\").str[0].str.strip().str.lower()\n",
    "labels[\"ID\"] = labels[\"ID\"].astype(int)\n",
    "labels = labels.dropna(subset=[\"label\"])\n",
    "\n",
    "# Load texts from data/*.txt\n",
    "rows = []\n",
    "id_pattern = re.compile(r\"^(\\d+)\\.txt$\")\n",
    "\n",
    "for p in DATA_DIR.glob(\"*.txt\"):\n",
    "    m = id_pattern.match(p.name)\n",
    "    if not m:\n",
    "        continue\n",
    "    _id = int(m.group(1))\n",
    "    # Tweets can contain emojis or unusual chars; ignore decoding errors safely\n",
    "    text = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "    rows.append((_id, text))\n",
    "\n",
    "texts = pd.DataFrame(rows, columns=[\"ID\", \"text\"])\n",
    "\n",
    "# Merge text + label\n",
    "df = texts.merge(labels[[\"ID\", \"label\"]], on=\"ID\", how=\"inner\")\n",
    "df = df[[\"text\", \"label\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Merged dataset shape:\", df.shape)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.2).\n",
      "Path to dataset files: C:\\Users\\mhjv_\\.cache\\kagglehub\\datasets\\vincemarcs\\mvsasingle\\versions\\1\n",
      "MVSA_ROOT: C:\\Users\\mhjv_\\.cache\\kagglehub\\datasets\\vincemarcs\\mvsasingle\\versions\\1\\MVSA_Single\n",
      "LABEL_FILE: C:\\Users\\mhjv_\\.cache\\kagglehub\\datasets\\vincemarcs\\mvsasingle\\versions\\1\\MVSA_Single\\labelResultAll.txt\n",
      "DATA_DIR: C:\\Users\\mhjv_\\.cache\\kagglehub\\datasets\\vincemarcs\\mvsasingle\\versions\\1\\MVSA_Single\\data\n",
      "Merged dataset shape: (4869, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text     label\n",
       "0       How I feel today #legday #jelly #aching #gym   neutral\n",
       "1  @ArrivaTW absolute disgrace two carriages from...  negative\n",
       "2  This is my Valentine's from 1 of my nephews. I...  positive\n",
       "3  betterfeelingfilms: RT via Instagram: First da...  positive\n",
       "4          Zoe's first love #Rattled @JohnnyHarper15  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How I feel today #legday #jelly #aching #gym</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArrivaTW absolute disgrace two carriages from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is my Valentine's from 1 of my nephews. I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betterfeelingfilms: RT via Instagram: First da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zoe's first love #Rattled @JohnnyHarper15</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "d2621e83",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Quick Exploratory Data Analysis (EDA)\n",
    "\n",
    "We inspect:\n",
    "- Label distribution\n",
    "- A few example texts\n",
    "\n",
    "This helps us understand class imbalance and the kind of noise present (mentions, hashtags, URLs, slang).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "56867644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T07:45:49.376428Z",
     "start_time": "2026-02-06T07:45:49.368096Z"
    }
   },
   "source": [
    "# Label distribution\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "label_dist = (label_counts / len(df)).round(4)\n",
    "\n",
    "display(pd.DataFrame({\"count\": label_counts, \"ratio\": label_dist}))\n",
    "\n",
    "# Show a few random examples\n",
    "df.sample(5, random_state=RANDOM_STATE)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          count   ratio\n",
       "label                  \n",
       "neutral    1921  0.3945\n",
       "positive   1731  0.3555\n",
       "negative   1217  0.2499"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1921</td>\n",
       "      <td>0.3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1731</td>\n",
       "      <td>0.3555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1217</td>\n",
       "      <td>0.2499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "                                                   text     label\n",
       "3861  RT @The4GNet: Black Pastor Protests Outside NA...   neutral\n",
       "1101  #Wiserswhiskeyquestionoftheday Cheerful Valent...  positive\n",
       "1149  Top chef even when I'm crippled, just need the...  positive\n",
       "4135  ˤQ | Mocha106b #pixiv http://t.co/sp4d7R5EnN h...   neutral\n",
       "1721  RT @TheBloggess: That moment when you have a t...  negative"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>RT @The4GNet: Black Pastor Protests Outside NA...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>#Wiserswhiskeyquestionoftheday Cheerful Valent...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Top chef even when I'm crippled, just need the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>ˤQ | Mocha106b #pixiv http://t.co/sp4d7R5EnN h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>RT @TheBloggess: That moment when you have a t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "02c1cd7b",
   "metadata": {},
   "source": [
    "\n",
    "## 4) English Subset Filtering\n",
    "\n",
    "MVSA-Single contains multiple languages. To make our experiments cleaner and to align with the project requirement,\n",
    "we filter to an **English subset** once, then run all ablations on the same subset.\n",
    "\n",
    "We implement English filtering using:\n",
    "- Preferred: `langdetect` (if installed)\n",
    "- Fallback: a simple **ASCII ratio heuristic** if `langdetect` is unavailable\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "804cbace",
   "metadata": {},
   "source": [
    "# =========================\n",
    "# 4) English Detection Helpers\n",
    "# =========================\n",
    "\n",
    "_whitespace_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize_text_basic(text: str) -> str:\n",
    "    # Minimal normalization shared by all experiments:\n",
    "    # - Replace line breaks with spaces\n",
    "    # - Collapse repeated whitespace\n",
    "    # - Trim leading/trailing spaces\n",
    "    text = \"\" if text is None else str(text)\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    text = _whitespace_re.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def is_english_langdetect(text: str) -> Optional[bool]:\n",
    "    # Return True/False using langdetect if available.\n",
    "    # Return None if langdetect is not installed.\n",
    "    try:\n",
    "        from langdetect import detect\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    t = normalize_text_basic(text)\n",
    "    if len(t) < 3:\n",
    "        return False\n",
    "    try:\n",
    "        return detect(t) == \"en\"\n",
    "    except Exception:\n",
    "        # langdetect can fail on very short or noisy strings\n",
    "        return False\n",
    "\n",
    "def is_english_ascii_heuristic(text: str, threshold: float = 0.90) -> bool:\n",
    "    # Fallback heuristic:\n",
    "    # - Count the fraction of ASCII characters\n",
    "    # - If ratio >= threshold, treat as English-like\n",
    "    t = normalize_text_basic(text)\n",
    "    if not t:\n",
    "        return False\n",
    "    ascii_chars = sum(1 for c in t if ord(c) < 128)\n",
    "    return (ascii_chars / max(1, len(t))) >= threshold\n",
    "\n",
    "def is_english(text: str) -> bool:\n",
    "    r = is_english_langdetect(text)\n",
    "    if r is None:\n",
    "        return is_english_ascii_heuristic(text)\n",
    "    return bool(r)\n",
    "\n",
    "# Apply English filtering\n",
    "df[\"is_english\"] = df[\"text\"].apply(is_english)\n",
    "df_en = df.loc[df[\"is_english\"]].drop(columns=[\"is_english\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Before English filter:\", len(df))\n",
    "print(\"After English filter:\", len(df_en))\n",
    "\n",
    "display(df_en[\"label\"].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "628b1219",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Preprocessing Functions (Used in Ablations)\n",
    "\n",
    "We implement the preprocessing steps required by the experiments:\n",
    "\n",
    "### (A) Remove social tokens\n",
    "Remove tokens starting with:\n",
    "- `@` (mentions)\n",
    "- `#` (hashtags)\n",
    "- `http` (URLs)\n",
    "\n",
    "### (B) Slang expansion\n",
    "Replace common social-media abbreviations using a dictionary, e.g.:\n",
    "- `lol` → `laugh out loud`\n",
    "- `idk` → `i do not know`\n",
    "\n",
    "### (C) Full preprocessing (E4)\n",
    "Combine:\n",
    "- remove social tokens\n",
    "- slang expansion\n",
    "and also apply class weighting during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c3b7f39",
   "metadata": {},
   "source": [
    "# =========================\n",
    "# 5) Preprocessing Functions\n",
    "# =========================\n",
    "\n",
    "# Token pattern: sequences of non-space characters\n",
    "_token_re = re.compile(r\"\\b\\S+\\b\", flags=re.UNICODE)\n",
    "\n",
    "def remove_social_tokens(text: str) -> str:\n",
    "    # Remove tokens that start with '@', '#', or 'http'.\n",
    "    # This is common for tweet-like data where mentions/hashtags/URLs can add noise.\n",
    "    t = normalize_text_basic(text)\n",
    "    tokens = _token_re.findall(t)\n",
    "    kept = []\n",
    "    for tok in tokens:\n",
    "        low = tok.lower()\n",
    "        if low.startswith(\"@\") or low.startswith(\"#\") or low.startswith(\"http\"):\n",
    "            continue\n",
    "        kept.append(tok)\n",
    "    return \" \".join(kept)\n",
    "\n",
    "# A small, editable slang dictionary (you can extend this list as needed)\n",
    "SLANG_DICT: Dict[str, str] = {\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"idk\": \"i do not know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"imho\": \"in my humble opinion\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"pls\": \"please\",\n",
    "    \"plz\": \"please\",\n",
    "    \"w/\": \"with\",\n",
    "    \"w/o\": \"without\",\n",
    "}\n",
    "\n",
    "# Lowercase keys for case-insensitive matching\n",
    "SLANG_DICT = {k.lower(): v for k, v in SLANG_DICT.items()}\n",
    "\n",
    "def expand_slang(text: str, slang: Dict[str, str] = SLANG_DICT) -> str:\n",
    "    # Replace slang tokens by dictionary expansion (token-by-token).\n",
    "    t = normalize_text_basic(text)\n",
    "    tokens = _token_re.findall(t)\n",
    "    out = []\n",
    "    for tok in tokens:\n",
    "        repl = slang.get(tok.lower())\n",
    "        out.append(repl if repl is not None else tok)\n",
    "    return \" \".join(out)\n",
    "\n",
    "def full_preprocess(text: str) -> str:\n",
    "    # FULL preprocessing used in E4:\n",
    "    # 1) Remove social tokens\n",
    "    # 2) Expand slang\n",
    "    t = remove_social_tokens(text)\n",
    "    t = expand_slang(t, SLANG_DICT)\n",
    "    return t\n",
    "\n",
    "# Quick sanity check\n",
    "sample_text = \"@user lol check this out http://example.com #happy\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Remove social:\", remove_social_tokens(sample_text))\n",
    "print(\"Slang expand:\", expand_slang(sample_text))\n",
    "print(\"FULL:\", full_preprocess(sample_text))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "509d5120",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Feature Engineering and Model\n",
    "\n",
    "### TF‑IDF Features\n",
    "We convert texts into sparse vectors using **TF‑IDF** with word n‑grams (1–2 grams).\n",
    "\n",
    "### Logistic Regression Classifier\n",
    "We train a **multiclass Logistic Regression** model on TF‑IDF features.\n",
    "\n",
    "For the class imbalance experiment (E3 and E4), we use:\n",
    "- `class_weight=\"balanced\"`\n",
    "\n",
    "This reweights the loss so minority classes receive higher weight, often improving **Macro-F1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1163626e",
   "metadata": {},
   "source": [
    "# =========================\n",
    "# 6) Train/Test Split (Stratified) + Model Builder\n",
    "# =========================\n",
    "\n",
    "LABEL_MAP = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "df_en_num = df_en.copy()\n",
    "df_en_num[\"y\"] = df_en_num[\"label\"].map(LABEL_MAP)\n",
    "\n",
    "# Drop any unexpected labels (safe-guard)\n",
    "df_en_num = df_en_num.dropna(subset=[\"y\"]).reset_index(drop=True)\n",
    "df_en_num[\"y\"] = df_en_num[\"y\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_en_num[\"text\"].values,\n",
    "    df_en_num[\"y\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df_en_num[\"y\"].values,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))\n",
    "print(\"Train label distribution:\", pd.Series(y_train).value_counts().to_dict())\n",
    "print(\"Test  label distribution:\", pd.Series(y_test).value_counts().to_dict())\n",
    "\n",
    "def build_pipeline(class_weight: Optional[str] = None) -> Pipeline:\n",
    "    # Build TF-IDF + Logistic Regression.\n",
    "    # Parameters are fixed across experiments for fair comparison.\n",
    "    tfidf = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    )\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=2000,\n",
    "        C=1.0,\n",
    "        class_weight=class_weight,\n",
    "        n_jobs=-1,\n",
    "        multi_class=\"auto\",\n",
    "    )\n",
    "\n",
    "    return Pipeline([(\"tfidf\", tfidf), (\"lr\", lr)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d938dcdf",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Run Ablation Experiments (E0–E4)\n",
    "\n",
    "We evaluate each experiment using:\n",
    "- Accuracy\n",
    "- Macro-F1\n",
    "- Confusion Matrix\n",
    "\n",
    "We also compute **Δ (improvement)** relative to the baseline E0.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "92fd255d",
   "metadata": {},
   "source": [
    "# =========================\n",
    "# 7) Experiment Runner\n",
    "# =========================\n",
    "\n",
    "TextTransform = Callable[[str], str]\n",
    "\n",
    "def apply_transform(texts: np.ndarray, transform: Optional[TextTransform]) -> List[str]:\n",
    "    # Apply a text transform (if provided) to an array of texts.\n",
    "    # We always apply normalize_text_basic for stable vectorization.\n",
    "    if transform is None:\n",
    "        return [normalize_text_basic(t) for t in texts]\n",
    "    return [transform(t) for t in texts]\n",
    "\n",
    "def evaluate_experiment(\n",
    "    exp_id: str,\n",
    "    name: str,\n",
    "    transform: Optional[TextTransform],\n",
    "    class_weight: Optional[str],\n",
    ") -> Dict:\n",
    "    # Train and evaluate one experiment, returning metrics and confusion matrix.\n",
    "    Xtr = apply_transform(X_train, transform)\n",
    "    Xte = apply_transform(X_test, transform)\n",
    "\n",
    "    model = build_pipeline(class_weight=class_weight)\n",
    "    model.fit(Xtr, y_train)\n",
    "\n",
    "    y_pred = model.predict(Xte)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"exp_id\": exp_id,\n",
    "        \"name\": name,\n",
    "        \"accuracy\": float(acc),\n",
    "        \"macro_f1\": float(macro),\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, title: str) -> None:\n",
    "    # Plot confusion matrix using matplotlib only.\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.colorbar()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define experiments (E0–E4)\n",
    "experiments = [\n",
    "    (\"E0\", \"Raw (English subset)\", None, None),\n",
    "    (\"E1\", \"Raw + remove @/#/url tokens\", remove_social_tokens, None),\n",
    "    (\"E2\", \"Raw + slang expansion\", lambda t: expand_slang(t, SLANG_DICT), None),\n",
    "    (\"E3\", \"Raw + class_weight=balanced\", None, \"balanced\"),\n",
    "    (\"E4\", \"FULL: remove @/#/url + slang + class_weight\", full_preprocess, \"balanced\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "cms = {}\n",
    "\n",
    "for exp_id, name, transform, cw in experiments:\n",
    "    print(f\"Running {exp_id}: {name}\")\n",
    "    out = evaluate_experiment(exp_id, name, transform, cw)\n",
    "    results.append({k: out[k] for k in [\"exp_id\", \"name\", \"accuracy\", \"macro_f1\"]})\n",
    "    cms[exp_id] = out[\"confusion_matrix\"]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Improvements vs E0 baseline\n",
    "base_acc = float(results_df.loc[results_df[\"exp_id\"] == \"E0\", \"accuracy\"].iloc[0])\n",
    "base_f1  = float(results_df.loc[results_df[\"exp_id\"] == \"E0\", \"macro_f1\"].iloc[0])\n",
    "results_df[\"delta_accuracy_vs_E0\"] = results_df[\"accuracy\"] - base_acc\n",
    "results_df[\"delta_macro_f1_vs_E0\"] = results_df[\"macro_f1\"] - base_f1\n",
    "\n",
    "results_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e5e01f0",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Results Analysis\n",
    "\n",
    "We interpret metrics as:\n",
    "- **Accuracy**: overall correctness (may be influenced by majority classes)\n",
    "- **Macro-F1**: average F1 across classes, treating each class equally\n",
    "\n",
    "We visualize confusion matrices for:\n",
    "- Baseline **E0**\n",
    "- Full pipeline **E4**\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a4768c5",
   "metadata": {},
   "source": [
    "display(results_df.sort_values(\"exp_id\").reset_index(drop=True))\n",
    "\n",
    "plot_confusion_matrix(cms[\"E0\"], \"Confusion Matrix - E0 (Raw)\")\n",
    "plot_confusion_matrix(cms[\"E4\"], \"Confusion Matrix - E4 (FULL)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5538186",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Optional: Error Analysis (Inspect Misclassifications)\n",
    "\n",
    "To better understand *why* preprocessing helps, we can inspect a few misclassified examples\n",
    "(using the FULL pipeline E4).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fe8822f",
   "metadata": {},
   "source": [
    "# Re-run E4 to explicitly obtain predictions (kept explicit for clarity)\n",
    "e4_pred = evaluate_experiment(\n",
    "    exp_id=\"E4\",\n",
    "    name=\"FULL: remove @/#/url + slang + class_weight\",\n",
    "    transform=full_preprocess,\n",
    "    class_weight=\"balanced\",\n",
    ")[\"y_pred\"]\n",
    "\n",
    "inv_label_map = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "err_df = pd.DataFrame({\n",
    "    \"text\": X_test,\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": e4_pred,\n",
    "})\n",
    "err_df[\"true_label\"] = err_df[\"y_true\"].map(inv_label_map)\n",
    "err_df[\"pred_label\"] = err_df[\"y_pred\"].map(inv_label_map)\n",
    "\n",
    "errors = err_df[err_df[\"y_true\"] != err_df[\"y_pred\"]].copy()\n",
    "print(\"Number of errors (E4):\", len(errors))\n",
    "\n",
    "# Show a few random errors\n",
    "errors.sample(min(10, len(errors)), random_state=RANDOM_STATE)[[\"true_label\", \"pred_label\", \"text\"]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b23645e",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Conclusion\n",
    "\n",
    "This notebook provides a clean, reproducible pipeline to evaluate **text preprocessing** impact on a **Logistic Regression** sentiment model.\n",
    "\n",
    "Suggested report takeaways:\n",
    "1. TF-IDF + Logistic Regression is a strong and interpretable baseline for text sentiment.\n",
    "2. Individual preprocessing steps can yield incremental improvements.\n",
    "3. The **FULL** pipeline (E4) often provides the best improvement, especially in **Macro-F1** when combined with class weighting.\n",
    "4. Pipeline Safety: All transformations were encapsulated in a pipeline, strictly adhering to the Golden Rule of Train-Test splitting to prevent data leakage.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
